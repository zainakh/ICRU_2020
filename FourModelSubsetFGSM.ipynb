{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from nn_robust_attacks.setup_mnist import MNIST, MNISTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto())\n",
    "K.set_session(sess)\n",
    "\n",
    "data = MNIST()\n",
    "\n",
    "# CNN Model for MNIST \n",
    "class MNIST_Model:\n",
    "    def __init__(self, session=None):\n",
    "        self.num_channels = 1\n",
    "        self.image_size = 28\n",
    "        self.num_labels = 10\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, (3, 3),\n",
    "                         input_shape=(28, 28, 1)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(32, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(10))\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training variables\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "train_temp = 1\n",
    "\n",
    "training = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def fn(correct, predicted):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
    "                                                   logits=predicted/train_temp)\n",
    "\n",
    "# Train first model \n",
    "modelname = \"models/trained_model1\"\n",
    "model1 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model1.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model1.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    model1.model.save(modelname)\n",
    "else:\n",
    "    model1.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "        \n",
    "model1.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train second model \n",
    "modelname = \"models/trained_model2\"\n",
    "model2 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model2.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model2.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    model2.model.save(modelname)\n",
    "else:\n",
    "    model2.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "    \n",
    "model2.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train third model \n",
    "modelname = \"models/trained_model3\"\n",
    "model3 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model3.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model3.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    model3.model.save(modelname)   \n",
    "else:\n",
    "    model3.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "    \n",
    "model3.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train fourth model \n",
    "modelname = \"models/trained_model4\"\n",
    "model4 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model4.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model4.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    model4.model.save(modelname)\n",
    "else:\n",
    "    model4.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "    \n",
    "model4.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train fifth model \n",
    "modelname = \"models/trained_model5\"\n",
    "model5 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model5.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model5.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    model5.model.save(modelname)\n",
    "else:\n",
    "    model5.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "    \n",
    "model5.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess / Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist as data_keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = data_keras.load_data()\n",
    "x_train = x_train[...,np.newaxis] /255.0\n",
    "x_test = x_test[...,np.newaxis] / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 382us/step\n",
      "loss=0.060424025029380574, accuracy=0.9833999872207642\n",
      "10000/10000 [==============================] - 3s 342us/step\n",
      "loss=0.060767219057303735, accuracy=0.9829999804496765\n",
      "10000/10000 [==============================] - 4s 370us/step\n",
      "loss=0.1604284207782708, accuracy=0.9513999819755554\n",
      "10000/10000 [==============================] - 4s 372us/step\n",
      "loss=0.06374289788251045, accuracy=0.979200005531311\n",
      "10000/10000 [==============================] - 4s 392us/step\n",
      "loss=0.1024473569555208, accuracy=0.9670000076293945\n"
     ]
    }
   ],
   "source": [
    "# Model performances\n",
    "scores = model1.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))\n",
    "\n",
    "scores = model2.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))\n",
    "\n",
    "scores = model3.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))\n",
    "\n",
    "scores = model4.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))\n",
    "\n",
    "scores = model5.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.set_cmap('Greys_r')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = 0\n",
    "num_img = 25\n",
    "\n",
    "targets = np.array([to_categorical(9)])\n",
    "for i in range(0, num_img - 1):\n",
    "    targets = np.vstack([targets, np.array(to_categorical(9))])\n",
    "\n",
    "targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adversarial(inputs, adv):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    ax2.axis('off')\n",
    "    ax2.imshow(inputs[0][:,:,0])\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(adv[0][:,:,0])\n",
    "    ax3.axis('off')\n",
    "    ax3.imshow(adv[0][:,:,0] - inputs[0][:,:,0])\n",
    "    ax1.margins(0,0)\n",
    "    ax2.margins(0,0)\n",
    "    ax3.margins(0,0)\n",
    "    #fig.savefig('attack_example_FGSM.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "\n",
    "def save_results(inputs, adv, targets, targets2, targets3, subset_attacked):\n",
    "    np.save('three_subset_data/inputs_three_FGSM_' + '_' + subset_attacked + '.csv', inputs)\n",
    "    np.save('three_subset_data/adv_three_FGSM_' + subset_attacked + '.csv', adv)\n",
    "    np.save('three_subset_data/targets_three_FGSM_' + subset_attacked + '.csv', targets)  \n",
    "    np.save('three_subset_data/targets2_three_FGSM_' + subset_attacked + '.csv', targets2)  \n",
    "    np.save('three_subset_data/targets3_three_FGSM_' + subset_attacked + '.csv', targets3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_confidence(image, model):\n",
    "    image = image[0]\n",
    "    pr = model.predict(image)\n",
    "    pr = np.array([np.exp(x) for x in pr])\n",
    "    pr = pr / np.sum(pr)\n",
    "    image_class = model.predict_classes(image)\n",
    "    return image_class[0], max(max(pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_evaluation(num_img, adv, num_models):\n",
    "    l = []\n",
    "    for i in range(0, num_img):\n",
    "        print(i)\n",
    "        if num_models == 1:\n",
    "            res = get_label_confidence(adv[i][np.newaxis, ...], model1.model)\n",
    "        if num_models > 1: \n",
    "            res = [get_label_confidence(adv[i][np.newaxis, ...], model1.model), get_label_confidence(adv[i][np.newaxis, ...], model2.model), get_label_confidence(adv[i][np.newaxis, ...], model3.model)]\n",
    "        print(res)\n",
    "        l.append(res)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_of_attack(adv, inputs, num_img):\n",
    "    perturb = adv - inputs\n",
    "    perturb_mean =  np.sum(perturb) / num_img \n",
    "    perturb_std = np.std(np.array([sum(x) for x in perturb]))\n",
    "    print('Mean', perturb_mean)\n",
    "    print('Standard Deviation', perturb_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transferability(num_img, adv):\n",
    "    for i in range(0, num_img):\n",
    "        print(i)\n",
    "        print('Model 5', get_label_confidence(adv[i][np.newaxis, ...], model5.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correct_four(subset, num_img, adv, num_models, targets, targets2, targets3, targets4, true_label='0'):\n",
    "    l = attack_evaluation(num_img, adv, num_models)\n",
    "    correct = []\n",
    "    for idx, res in enumerate(l):\n",
    "        if subset == '1':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == true_label and res[2][0] == true_label and res[3][0] == true_label else False\n",
    "        elif subset == '2':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == true_label and res[3][0] == true_label else False\n",
    "        elif subset == '3':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == true_label and res[2][0] == np.nonzero(targets3[idx]) and res[3][0] == true_label else False\n",
    "        elif subset == '4':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == true_label and res[2][0] == true_label and res[3][0] == np.nonzero(targets4[idx]) else False\n",
    "        elif subset == '12':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == true_label and res[3][0] == true_label else False\n",
    "        elif subset == '13':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == true_label and res[2][0] == np.nonzero(targets3[idx]) and res[3][0] == true_label else False\n",
    "        elif subset == '14':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == true_label and res[2][0] == true_label and res[3][0] == np.nonzero(targets4[idx]) else False\n",
    "        elif subset == '23':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == np.nonzero(targets3[idx]) and res[3][0] == true_label else False\n",
    "        elif subset == '24':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == true_label and res[3][0] == np.nonzero(targets4[idx]) else False\n",
    "        elif subset == '34':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == true_label and res[2][0] == np.nonzero(targets3[idx]) and res[3][0] == np.nonzero(targets4[idx]) else False\n",
    "        elif subset == '123':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == np.nonzero(targets3[idx]) and res[3][0] == true_label else False\n",
    "        elif subset == '124':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == true_label and res[3][0] == np.nonzero(targets4[idx]) else False\n",
    "        elif subset == '134':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == true_label and res[2][0] == np.nonzero(targets3[idx]) and res[3][0] == np.nonzero(targets4[idx]) else False\n",
    "        elif subset == '234':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == np.nonzero(targets3[idx]) and res[3][0] == np.nonzero(targets4[idx]) else False\n",
    "        elif subset == '1234':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == np.nonzero(targets3[idx]) and res[3][0] == np.nonzero(targets4[idx]) else False\n",
    "            \n",
    "        if output:\n",
    "            correct.append(l.index(res))\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correct(subset, num_img, adv, num_models, targets, targets2, targets3, true_label='0'):\n",
    "    l = attack_evaluation(num_img, adv, num_models)\n",
    "    correct = []\n",
    "    for idx, res in enumerate(l):\n",
    "        if subset == '1':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == true_label and res[2][0] == true_label else False\n",
    "        elif subset == '2':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == true_label else False\n",
    "        elif subset == '3':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == true_label and res[2][0] == np.nonzero(targets3[idx]) else False\n",
    "        elif subset == '12':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == true_label else False\n",
    "        elif subset == '13':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == true_label and res[2][0] == np.nonzero(targets3[idx]) else False\n",
    "        elif subset == '23':\n",
    "            output = True if res[0][0] == true_label and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == np.nonzero(targets3[idx]) else False\n",
    "        elif subset == '123':\n",
    "            output = True if res[0][0] == np.nonzero(targets[idx]) and res[1][0] == np.nonzero(targets2[idx]) and res[2][0] == np.nonzero(targets3[idx]) else False\n",
    "            \n",
    "        if output:\n",
    "            correct.append(l.index(res))\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(num_img, adv, num_models, inputs, subset, targets, targets2, targets3):\n",
    "    print(check_correct(subset, num_img, adv, num_models, targets, targets2, targets3))\n",
    "    print(size_of_attack(adv, inputs, num_img))\n",
    "    print(transferability(num_img, adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(inputs, subset, targets, targets2, targets3, epochs=30, epsilon=0.33, true_class=0):\n",
    "    print('Going up to ' + str(len(inputs)) + ' for ' + str(epochs) + ' iterations each')\n",
    "    \n",
    "    adv = []\n",
    "    graphX = tf.Graph() # every time you overwrite it\n",
    "    \n",
    "    with graphX.as_default():\n",
    "        with tf.Session(graph=graphX) as sess:\n",
    "            model1.model = load_model(\"models/trained_model1\", custom_objects={'fn':fn})\n",
    "            model2.model = load_model(\"models/trained_model2\", custom_objects={'fn':fn})\n",
    "            model3.model = load_model(\"models/trained_model3\", custom_objects={'fn':fn})\n",
    "            model4.model = load_model(\"models/trained_model4\", custom_objects={'fn':fn})\n",
    "            model5.model = load_model(\"models/trained_model5\", custom_objects={'fn':fn})\n",
    "    \n",
    "            for j, x in enumerate(inputs):\n",
    "                print(j)\n",
    "                \n",
    "                true = K.one_hot(true_class, 10)\n",
    "                x = inputs[j:j+1]\n",
    "                x_adv = x\n",
    "                x_noise = np.zeros_like(x)\n",
    "\n",
    "                if '1' not in subset:\n",
    "                    targets[j] = 0\n",
    "                    targets[j][0] = 1\n",
    "\n",
    "                if '2' not in subset:\n",
    "                    targets2[j] = 0\n",
    "                    targets2[j][0] = 1\n",
    "\n",
    "                if '3' not in subset:\n",
    "                    targets3[j] = 0\n",
    "                    targets3[j][0] = 1\n",
    "\n",
    "                if '4' not in subset:\n",
    "                    targets4[j] = 0\n",
    "                    targets4[j][0] = 1\n",
    "\n",
    "                for i in range(epochs): \n",
    "                    # Get the loss and gradient of the loss wrt the inputs     \n",
    "                    target1 = K.one_hot(np.nonzero(targets[j])[0][0], 10)\n",
    "                    target2 = K.one_hot(np.nonzero(targets2[j])[0][0], 10)\n",
    "                    target3 = K.one_hot(np.nonzero(targets3[j])[0][0], 10)\n",
    "                    #target4 = K.one_hot(np.nonzero(targets4[j])[0][0], 10)\n",
    "\n",
    "                    loss = -1 * K.categorical_crossentropy(target1, K.softmax(model1.model.output)) \n",
    "                    loss2 = -1 * K.categorical_crossentropy(target2, K.softmax(model2.model.output))\n",
    "                    loss3 = -1 * K.categorical_crossentropy(target3, K.softmax(model3.model.output))\n",
    "                    #loss4 = -1 * K.categorical_crossentropy(target4, K.softmax(model4.model.output))\n",
    "\n",
    "                    grads = K.gradients(loss, model1.model.input)\n",
    "                    grads2 = K.gradients(loss2, model2.model.input)\n",
    "                    grads3 = K.gradients(loss3, model3.model.input)\n",
    "                    #grads4 = K.gradients(loss4, model4.model.input)\n",
    "\n",
    "                    # Get the sign of the gradient\n",
    "                    delta = K.sign(grads[0]) + K.sign(grads2[0]) + K.sign(grads3[0]) #+ K.sign(grads4[0])\n",
    "                    x_noise = x_noise + delta\n",
    "\n",
    "                    # Perturb the image\n",
    "                    x_adv = x_adv + epsilon * delta\n",
    "\n",
    "                    # Get the new image and predictions\n",
    "                    x_adv = sess.run(x_adv, feed_dict={model1.model.input:x, model2.model.input:x, model3.model.input:x })#, model4.model.input:x})\n",
    "\n",
    "                    preds = model1.model.predict(x_adv)\n",
    "                    preds2 = model2.model.predict(x_adv)\n",
    "                    preds3 = model3.model.predict(x_adv)\n",
    "                    #preds4 = model4.model.predict(x_adv)\n",
    "\n",
    "                    if(np.nonzero(targets[j])[0][0] == np.argmax(preds[0]) and np.nonzero(targets2[j])[0][0] == np.argmax(preds2[0]) and np.nonzero(targets3[j])[0][0] == np.argmax(preds3[0])): #and np.nonzero(targets4[j])[0][0] == np.argmax(preds4[0])):\n",
    "                        break\n",
    "\n",
    "                    x = x_adv\n",
    "\n",
    "                adv.append(x)\n",
    "\n",
    "            adv = np.array(adv)\n",
    "            save_results(inputs, adv, targets, targets2, targets3, subset)\n",
    "    \n",
    "    return adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.load('label_9_targets_25_img.csv.npy')\n",
    "targets2 = np.load('label_9_targets_25_img.csv.npy')\n",
    "targets3 = np.load('label_9_targets_25_img.csv.npy')\n",
    "targets4 = np.load('label_9_targets_25_img.csv.npy')\n",
    "inputs = np.load('inputs_0.csv.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM One Attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = '1'\n",
    "adv = FGSM(inputs[0:2], subset, targets, targets2, targets3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_17_input to have 4 dimensions, but got array with shape (1, 1, 28, 28, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-0313e0029ad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-776ab46d1b3d>\u001b[0m in \u001b[0;36mprint_results\u001b[0;34m(num_img, adv, num_models, inputs, subset, targets, targets2, targets3)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_of_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransferability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-4c9f39607070>\u001b[0m in \u001b[0;36mcheck_correct\u001b[0;34m(subset, num_img, adv, num_models, targets, targets2, targets3, true_label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-db6a2b88f130>\u001b[0m in \u001b[0;36mattack_evaluation\u001b[0;34m(num_img, adv, num_models)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_label_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_models\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_label_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_label_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_label_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-0d3e385d4fbc>\u001b[0m in \u001b[0;36mget_label_confidence\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_label_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#image = image[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/xu-jXQ59E2g/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/xu-jXQ59E2g/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/xu-jXQ59E2g/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_17_input to have 4 dimensions, but got array with shape (1, 1, 28, 28, 1)"
     ]
    }
   ],
   "source": [
    "print_results(2, adv, 3, inputs, subset, targets, targets2, targets3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going up to 25 for 30 iterations each\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "0\n",
      "[(0, 1.0), (0, 0.9999992), (0, 1.0)]\n",
      "1\n",
      "[(0, 1.0), (0, 0.9998754), (0, 1.0)]\n",
      "2\n",
      "[(0, 1.0), (5, 0.86251205), (0, 1.0)]\n",
      "3\n",
      "[(0, 1.0), (0, 1.0), (0, 1.0)]\n",
      "4\n",
      "[(0, 1.0), (5, 0.99989146), (0, 0.9999999)]\n",
      "5\n",
      "[(0, 1.0), (0, 0.8182965), (0, 1.0)]\n",
      "6\n",
      "[(0, 1.0), (0, 1.0), (0, 1.0)]\n",
      "7\n",
      "[(0, 1.0), (0, 0.9999951), (0, 1.0)]\n",
      "8\n",
      "[(0, 1.0), (0, 0.9999893), (0, 0.9999988)]\n",
      "9\n",
      "[(0, 0.99999833), (5, 0.66794026), (0, 1.0)]\n",
      "10\n",
      "[(0, 1.0), (0, 0.8948682), (0, 1.0)]\n",
      "11\n",
      "[(3, 0.86949635), (9, 0.9408399), (9, 0.9999295)]\n",
      "12\n",
      "[(0, 0.9999996), (5, 0.9964337), (0, 1.0)]\n",
      "13\n",
      "[(0, 0.99999994), (0, 0.9997666), (0, 1.0)]\n",
      "14\n",
      "[(0, 1.0), (0, 0.98240596), (0, 1.0)]\n",
      "15\n",
      "[(0, 1.0), (0, 0.99978995), (0, 1.0)]\n",
      "16\n",
      "[(0, 1.0), (0, 0.99988747), (0, 1.0)]\n",
      "17\n",
      "[(0, 1.0), (0, 0.98921525), (0, 0.9999998)]\n",
      "18\n",
      "[(0, 0.99999994), (0, 0.9998089), (0, 1.0)]\n",
      "19\n",
      "[(0, 0.99999326), (0, 0.9337737), (0, 1.0)]\n",
      "20\n",
      "[(0, 0.9999998), (0, 0.9812108), (0, 1.0)]\n",
      "21\n",
      "[(7, 0.90750974), (5, 0.60707587), (0, 0.8295792)]\n",
      "22\n",
      "[(0, 1.0), (0, 0.5515917), (0, 1.0)]\n",
      "23\n",
      "[(0, 1.0), (0, 0.9972913), (0, 1.0)]\n",
      "24\n",
      "[(0, 1.0), (0, 0.9996283), (0, 1.0)]\n",
      "[]\n",
      "Mean 1472.45984375\n",
      "Standard Deviation 37.574627\n",
      "None\n",
      "0\n",
      "Model 5 (0, 0.99999535)\n",
      "1\n",
      "Model 5 (0, 0.9999267)\n",
      "2\n",
      "Model 5 (0, 0.99999946)\n",
      "3\n",
      "Model 5 (0, 1.0)\n",
      "4\n",
      "Model 5 (4, 0.9204075)\n",
      "5\n",
      "Model 5 (0, 0.9999998)\n",
      "6\n",
      "Model 5 (0, 1.0)\n",
      "7\n",
      "Model 5 (0, 1.0)\n",
      "8\n",
      "Model 5 (0, 0.99999976)\n",
      "9\n",
      "Model 5 (0, 0.52722377)\n",
      "10\n",
      "Model 5 (0, 0.99974674)\n",
      "11\n",
      "Model 5 (9, 0.99665827)\n",
      "12\n",
      "Model 5 (0, 0.6291023)\n",
      "13\n",
      "Model 5 (0, 0.999994)\n",
      "14\n",
      "Model 5 (0, 1.0)\n",
      "15\n",
      "Model 5 (0, 1.0)\n",
      "16\n",
      "Model 5 (0, 1.0)\n",
      "17\n",
      "Model 5 (0, 0.99999124)\n",
      "18\n",
      "Model 5 (0, 0.9999985)\n",
      "19\n",
      "Model 5 (0, 0.9999754)\n",
      "20\n",
      "Model 5 (0, 0.9999973)\n",
      "21\n",
      "Model 5 (4, 0.99414307)\n",
      "22\n",
      "Model 5 (0, 1.0)\n",
      "23\n",
      "Model 5 (0, 0.9999891)\n",
      "24\n",
      "Model 5 (0, 0.9999993)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "subset = '2'\n",
    "adv = FGSM(inputs, subset, targets, targets2, targets3)\n",
    "print_results(25, adv, 3, inputs, subset, targets, targets2, targets3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = '3'\n",
    "adv = FGSM(inputs, subset, targets, targets2, targets3)\n",
    "print_results(25, adv, 3, inputs, subset, targets, targets2, targets3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM Two Attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = '12'\n",
    "adv = FGSM(inputs, subset, targets, targets2, targets3)\n",
    "print_results(25, adv, 3, inputs, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = '13'\n",
    "adv = FGSM(inputs, subset, targets, targets2, targets3)\n",
    "print_results(25, adv, 3, inputs, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = '23'\n",
    "adv = FGSM(inputs, subset, targets, targets2, targets3)\n",
    "print_results(25, adv, 3, inputs, subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM Three Attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = '123'\n",
    "adv = FGSM(inputs, subset, targets, targets2, targets3)\n",
    "print_results(25, adv, 3, inputs, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
