{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from nn_robust_attacks.setup_mnist import MNIST, MNISTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto())\n",
    "K.set_session(sess)\n",
    "\n",
    "data = MNIST()\n",
    "\n",
    "class MNIST_Model:\n",
    "    def __init__(self, session=None):\n",
    "        self.num_channels = 1\n",
    "        self.image_size = 28\n",
    "        self.num_labels = 10\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, (3, 3),\n",
    "                         input_shape=(28, 28, 1)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(32, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(10))\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "train_temp = 1\n",
    "\n",
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zainkhan/.local/share/virtualenvs/xu-jXQ59E2g/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-7f54ad202288>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /home/zainkhan/.local/share/virtualenvs/xu-jXQ59E2g/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def fn(correct, predicted):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
    "                                                   logits=predicted/train_temp)\n",
    "\n",
    "# Train first model \n",
    "modelname = \"models/trained_model1\"\n",
    "model1 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model1.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model1.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "    model1.model.save(modelname)\n",
    "    \n",
    "else:\n",
    "    model1.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "        \n",
    "model1.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train second model \n",
    "modelname = \"models/trained_model2\"\n",
    "model2 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model2.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model2.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "    model2.model.save(modelname)\n",
    "    \n",
    "else:\n",
    "    model2.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "    \n",
    "model2.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train third model \n",
    "modelname = \"models/trained_model3\"\n",
    "model3 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model3.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model3.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "    model3.model.save(modelname)\n",
    "    \n",
    "else:\n",
    "    model3.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "    \n",
    "model3.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train fourth model \n",
    "modelname = \"models/trained_model4\"\n",
    "model4 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model4.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model4.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "    model4.model.save(modelname)\n",
    "    \n",
    "else:\n",
    "    model4.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "    \n",
    "model4.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zainkhan/.local/share/virtualenvs/xu-jXQ59E2g/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 36s 652us/step - loss: 0.4375 - accuracy: 0.8650 - val_loss: 0.0846 - val_accuracy: 0.9738\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 35s 638us/step - loss: 0.0683 - accuracy: 0.9786 - val_loss: 0.0595 - val_accuracy: 0.9818\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 43s 784us/step - loss: 0.0474 - accuracy: 0.9857 - val_loss: 0.0475 - val_accuracy: 0.9864\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 35s 637us/step - loss: 0.0357 - accuracy: 0.9885 - val_loss: 0.0449 - val_accuracy: 0.9864\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 35s 639us/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0438 - val_accuracy: 0.9866\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 35s 639us/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.0451 - val_accuracy: 0.9884\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 35s 639us/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0357 - val_accuracy: 0.9902\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 35s 642us/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.0388 - val_accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 35s 643us/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.0327 - val_accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 35s 642us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0366 - val_accuracy: 0.9906\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train fifth model \n",
    "modelname = \"models/trained_model5\"\n",
    "model5 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model5.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model5.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "    model5.model.save(modelname)\n",
    "    \n",
    "else:\n",
    "    model5.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "    \n",
    "model5.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zainkhan/.local/share/virtualenvs/xu-jXQ59E2g/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 36s 648us/step - loss: 0.5181 - accuracy: 0.8346 - val_loss: 0.0777 - val_accuracy: 0.9772\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 35s 638us/step - loss: 0.0708 - accuracy: 0.9777 - val_loss: 0.0621 - val_accuracy: 0.9824\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 35s 636us/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 0.0545 - val_accuracy: 0.9848\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 35s 637us/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 0.0432 - val_accuracy: 0.9880\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 35s 639us/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0447 - val_accuracy: 0.9884\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 35s 639us/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.0390 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 35s 638us/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0461 - val_accuracy: 0.9850\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 35s 639us/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0444 - val_accuracy: 0.9868\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 35s 642us/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.0418 - val_accuracy: 0.9868\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 35s 640us/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0402 - val_accuracy: 0.9900\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 312,202\n",
      "Trainable params: 312,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train sixth model \n",
    "modelname = \"models/trained_model6\"\n",
    "model6 = MNIST_Model()\n",
    "if training:            \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model6.model.compile(loss=fn,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model6.model.fit(data.train_data, data.train_labels,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(data.validation_data, data.validation_labels),\n",
    "              nb_epoch=num_epochs,\n",
    "              shuffle=True)\n",
    "    \n",
    "    model6.model.save(modelname)\n",
    "    \n",
    "else:\n",
    "    model6.model = load_model(modelname, custom_objects={'fn':fn})\n",
    "    \n",
    "model6.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist as data_keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = data_keras.load_data()\n",
    "x_train = x_train[...,np.newaxis] /255.0\n",
    "x_test = x_test[...,np.newaxis] / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 202us/step\n",
      "loss=0.060424025029380574, accuracy=0.9833999872207642\n",
      "10000/10000 [==============================] - 2s 192us/step\n",
      "loss=0.14029382344670593, accuracy=0.9559999704360962\n",
      "10000/10000 [==============================] - 2s 197us/step\n",
      "loss=0.1604284207782708, accuracy=0.9513999819755554\n",
      "10000/10000 [==============================] - 2s 200us/step\n",
      "loss=0.06374289788251045, accuracy=0.979200005531311\n",
      "10000/10000 [==============================] - 2s 199us/step\n",
      "loss=0.1024473569555208, accuracy=0.9670000076293945\n",
      "10000/10000 [==============================] - 2s 198us/step\n",
      "loss=0.12785435293135233, accuracy=0.9595999717712402\n"
     ]
    }
   ],
   "source": [
    "# Performance of first model\n",
    "scores = model1.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))\n",
    "\n",
    "# Performance of second model\n",
    "scores = model2.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))\n",
    "\n",
    "# Performance of third model\n",
    "scores = model3.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))\n",
    "\n",
    "# Performance of fourth model\n",
    "scores = model4.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))\n",
    "\n",
    "# Performance of fifth model\n",
    "scores = model5.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))\n",
    "\n",
    "# Performance of sixth model\n",
    "scores = model6.model.evaluate(x_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(*scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 250\n",
    "num_img = test_size // 10\n",
    "trial_data = []\n",
    "indicies = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    trial_data.append([])\n",
    "    indicies.append([])\n",
    "    for idx, img in enumerate(data.test_data):\n",
    "        if np.nonzero(data.test_labels[idx])[0][0] == i:\n",
    "            trial_data[i].append(data.test_data[idx])\n",
    "            indicies[i].append(idx)\n",
    "        if len(trial_data[i]) >= num_img:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "target_data = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    target_data.append([])\n",
    "    for j in range(0, int(num_img)):\n",
    "        numbers = list(range(0, i)) + list(range(i + 1, 10))\n",
    "        r = random.choice(numbers)\n",
    "        target_data[i].append(r)\n",
    "\n",
    "target_labels = []\n",
    "for i in range(0, 10):\n",
    "    target_labels.append(to_categorical(target_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.set_cmap('Greys_r')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = 0\n",
    "#inputs = np.asarray(trial_data[true_label])\n",
    "#targets = target_labels[true_label]\n",
    "\n",
    "targets = np.array([to_categorical(9)])\n",
    "for i in range(0, num_img - 1):\n",
    "    targets = np.vstack([targets, np.array(to_categorical(9))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets = np.load('targets_0.csv.npy')\n",
    "inputs = np.load('inputs_0.csv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zainkhan/research/xu/nn_robust_attacks/l2_attack_tri.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zainkhan/research/xu/nn_robust_attacks/l2_attack_tri.py:130: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zainkhan/.local/share/virtualenvs/xu-jXQ59E2g/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/zainkhan/research/xu/nn_robust_attacks/l2_attack_tri.py:141: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "go up to 25\n",
      "tick 0\n",
      "[10000000000.0]\n",
      "0 (0.043152444, 0.017142495, 0.0041285073)\n",
      "1000 (0.03922678, 0.017249895, 2.0019474e-05)\n",
      "2000 (0.039236493, 0.017248344, 3.234579e-05)\n",
      "[10000000000.0]\n",
      "0 (0.39440468, 0.17141984, 0.004175713)\n",
      "1000 (0.39032498, 0.17040783, 0.0021719919)\n",
      "2000 (0.3903252, 0.17045255, 0.002120975)\n",
      "[10000000000.0]\n",
      "0 (3.9064605, 1.7141917, 0.0041809315)\n",
      "1000 (3.6977599, 1.4907293, 0.21950853)\n",
      "2000 (3.6977258, 1.4938778, 0.21754563)\n",
      "[10000000000.0]\n",
      "0 (39.026966, 17.141909, 0.0041814726)\n",
      "1000 (11.291908, 0.0, 11.2313385)\n",
      "2000 (11.30395, 0.0, 11.202785)\n",
      "[11.128836]\n",
      "0 (21.466715, 9.428052, 0.0041814214)\n",
      "1000 (11.219787, 0.0544267, 8.85164)\n",
      "2000 (11.213367, 0.053397723, 8.837575)\n",
      "3000 (11.207996, 0.057002883, 8.849121)\n",
      "4000 (11.205105, 0.037849873, 8.86116)\n",
      "[8.870075]\n",
      "0 (12.686586, 5.571121, 0.004181344)\n",
      "1000 (9.560707, 2.0101385, 3.7262344)\n",
      "2000 (9.501265, 1.6964233, 3.8847313)\n",
      "3000 (9.505677, 1.6818237, 3.9234042)\n",
      "[8.870075]\n",
      "0 (17.076649, 7.499586, 0.0041813916)\n",
      "1000 (10.938477, 0.7675186, 6.7669454)\n",
      "2000 (10.936938, 0.7801791, 6.761079)\n",
      "3000 (10.92783, 0.7677435, 6.798568)\n",
      "4000 (10.928305, 0.78579587, 6.7795496)\n",
      "[8.870075]\n",
      "0 (19.271683, 8.463819, 0.004181409)\n",
      "1000 (10.973183, 0.1363551, 8.560654)\n",
      "2000 (10.985166, 0.19087721, 8.4778)\n",
      "[8.870075]\n",
      "0 (20.369202, 8.945935, 0.004181416)\n",
      "1000 (11.105298, 0.10225251, 8.559082)\n",
      "2000 (11.092394, 0.06515417, 8.616306)\n",
      "tick 1\n",
      "[10000000000.0]\n",
      "0 (0.05102788, 0.020723907, 0.005481097)\n",
      "1000 (0.045842566, 0.020871809, 1.6547772e-05)\n",
      "2000 (0.04584597, 0.020870656, 2.3230054e-05)\n",
      "[10000000000.0]\n",
      "0 (0.46109664, 0.20722802, 0.005640029)\n",
      "1000 (0.456731, 0.20708175, 0.0019211936)\n",
      "2000 (0.45673737, 0.20708807, 0.0019233902)\n",
      "[10000000000.0]\n",
      "0 (4.56022, 2.0722673, 0.0056660725)\n",
      "1000 (4.3894057, 1.918681, 0.20779845)\n",
      "2000 (4.3894453, 1.9189341, 0.2074064)\n",
      "[10000000000.0]\n",
      "0 (45.551178, 20.722658, 0.0056688692)\n",
      "1000 (9.96823, 0.0, 9.956722)\n",
      "2000 (9.907043, 0.030438043, 9.876605)\n",
      "3000 (9.864424, 0.0, 9.864424)\n",
      "4000 (9.942007, 0.0, 9.867002)\n",
      "5000 (9.864095, 0.0, 9.839315)\n",
      "[9.725868]\n",
      "0 (25.055704, 11.397462, 0.0056686094)\n",
      "1000 (9.769383, 0.10408073, 9.027511)\n",
      "2000 (9.715301, 0.02912932, 9.117713)\n",
      "3000 (9.767335, 0.14247356, 9.067731)\n",
      "[9.12096]\n",
      "0 (14.807962, 6.7348657, 0.0056682155)\n",
      "1000 (9.236386, 0.57604486, 7.627023)\n",
      "2000 (9.239504, 0.5878911, 7.622099)\n",
      "[9.12096]\n",
      "0 (19.931831, 9.066165, 0.0056684613)\n",
      "1000 (9.534972, 0.12776749, 8.655403)\n",
      "2000 (9.548572, 0.123268254, 8.708658)\n",
      "3000 (9.582672, 0.21443899, 8.541155)\n",
      "[9.12096]\n",
      "0 (22.493767, 10.2318125, 0.005668545)\n",
      "1000 (9.694071, 0.1730258, 8.834063)\n",
      "2000 (9.644888, 0.048313174, 8.952726)\n",
      "[9.007655]\n",
      "0 (21.212801, 9.64899, 0.0056685056)\n",
      "1000 (9.627677, 0.11765874, 8.8027)\n",
      "2000 (9.590034, 0.0709593, 8.865692)\n",
      "3000 (9.606783, 0.077713594, 8.834436)\n",
      "tick 2\n",
      "[10000000000.0]\n",
      "0 (0.044404466, 0.018138941, 0.005183667)\n",
      "1000 (0.039543465, 0.018296408, 2.3894936e-05)\n",
      "2000 (0.039546307, 0.018296296, 2.7899365e-05)\n",
      "[10000000000.0]\n",
      "0 (0.39751363, 0.18137021, 0.0053161234)\n",
      "1000 (0.39311814, 0.18066646, 0.0026007006)\n",
      "2000 (0.39312, 0.18066841, 0.0026009455)\n",
      "[10000000000.0]\n",
      "0 (3.9272985, 1.8136691, 0.005338017)\n",
      "1000 (3.6923196, 1.5649589, 0.28022993)\n",
      "2000 (3.6922894, 1.5643219, 0.28097722)\n",
      "[10000000000.0]\n",
      "0 (39.22493, 18.13666, 0.0053404)\n",
      "1000 (12.617412, 0.18598995, 10.366669)\n",
      "2000 (11.627953, 0.24485978, 10.635355)\n",
      "3000 (11.283875, 0.016531564, 10.988705)\n",
      "4000 (11.286582, 0.06063471, 11.023462)\n",
      "5000 (11.279454, 0.099189855, 11.005313)\n",
      "[10.383671]\n",
      "0 (21.576118, 9.975164, 0.005340182)\n",
      "1000 (10.619759, 1.2174693, 6.566415)\n",
      "2000 (10.618841, 1.188, 6.5985947)\n",
      "[10.383671]\n",
      "0 (30.400524, 14.055911, 0.0053403224)\n",
      "1000 (11.786983, 1.1240407, 8.973217)\n",
      "2000 (11.780655, 1.178312, 8.888435)\n",
      "[10.383671]\n",
      "0 (34.812725, 16.096283, 0.005340367)\n",
      "1000 (11.244396, 0.11704637, 10.026589)\n",
      "2000 (11.198089, 0.0, 10.099262)\n",
      "3000 (11.1908045, 0.020269759, 10.070551)\n",
      "[9.734653]\n",
      "0 (32.606625, 15.076098, 0.0053403457)\n",
      "1000 (12.104201, 0.06346699, 9.535126)\n",
      "2000 (12.062102, 0.035333376, 9.644665)\n",
      "3000 (12.058649, 0.03709207, 9.630772)\n",
      "[9.538247]\n",
      "0 (31.503574, 14.566007, 0.005340333)\n",
      "1000 (11.887258, 1.0524591, 9.051162)\n",
      "2000 (11.84859, 1.0414414, 9.094419)\n",
      "3000 (11.878899, 1.0849614, 9.040879)\n",
      "tick 3\n",
      "[10000000000.0]\n",
      "0 (0.029472357, 0.011659104, 0.004883617)\n",
      "1000 (0.024819609, 0.011750234, 2.4699768e-05)\n",
      "2000 (0.024819875, 0.0117497295, 2.7164675e-05)\n",
      "[10000000000.0]\n",
      "0 (0.2508077, 0.1165826, 0.004934838)\n",
      "1000 (0.24569485, 0.11497394, 0.002762626)\n",
      "2000 (0.24569967, 0.114954956, 0.0027969498)\n",
      "[10000000000.0]\n",
      "0 (2.4636548, 1.1658176, 0.004940219)\n",
      "1000 (2.2384505, 0.93806285, 0.22549202)\n",
      "2000 (2.2384408, 0.9382799, 0.22452642)\n",
      "[10000000000.0]\n",
      "0 (24.592068, 11.658166, 0.004940819)\n",
      "1000 (6.9283752, 0.0, 6.8509536)\n",
      "2000 (6.794751, 0.0, 6.769889)\n",
      "3000 (6.8244534, 0.024274923, 6.7639995)\n",
      "[6.3379683]\n",
      "0 (13.527862, 6.411992, 0.0049407566)\n",
      "1000 (6.647595, 0.12943895, 5.0441127)\n",
      "2000 (6.640045, 0.12002171, 5.0371566)\n",
      "3000 (6.6493154, 0.10216911, 5.040632)\n",
      "[6.3379683]\n",
      "0 (19.059969, 9.035081, 0.0049407957)\n",
      "1000 (7.007528, 0.027171519, 5.950593)\n",
      "2000 (7.0119753, 0.044750955, 5.9454594)\n",
      "3000 (6.9827757, 0.016534796, 5.945138)\n",
      "4000 (6.9848785, 0.0, 5.965496)\n",
      "5000 (6.983216, 0.021742478, 5.942642)\n",
      "[5.8687015]\n",
      "0 (16.293915, 7.7235365, 0.0049407813)\n",
      "1000 (6.8508763, 0.03509612, 5.414851)\n",
      "2000 (6.8515725, 0.0, 5.482005)\n",
      "3000 (6.8425274, 0.024129177, 5.459565)\n",
      "[5.4103413]\n",
      "0 (14.910888, 7.0677633, 0.0049407696)\n",
      "1000 (6.72748, 0.0049242903, 5.4921722)\n",
      "2000 (6.745739, 0.08836246, 5.3906674)\n",
      "[5.34981]\n",
      "0 (14.219376, 6.7398787, 0.004940764)\n",
      "1000 (6.67521, 0.06050912, 5.2549624)\n",
      "2000 (6.6553826, 0.044404943, 5.3211346)\n",
      "3000 (6.6762214, 0.04017559, 5.2687364)\n",
      "tick 4\n",
      "[10000000000.0]\n",
      "0 (0.047739983, 0.021251548, 0.004858719)\n",
      "1000 (0.04308653, 0.021370284, 1.7534345e-05)\n",
      "2000 (0.04309705, 0.021370033, 2.8874112e-05)\n",
      "[10000000000.0]\n",
      "0 (0.43379357, 0.21250543, 0.004994699)\n",
      "1000 (0.42915207, 0.21192712, 0.001960745)\n",
      "2000 (0.4291557, 0.21193126, 0.0019740732)\n",
      "[10000000000.0]\n",
      "0 (4.293049, 2.1250076, 0.0050614015)\n",
      "1000 (4.1079154, 1.9278897, 0.20718998)\n",
      "2000 (4.1078367, 1.9284728, 0.20708108)\n",
      "[10000000000.0]\n",
      "0 (42.884995, 21.249998, 0.0050750505)\n",
      "1000 (15.257822, 0.031242229, 12.865626)\n",
      "2000 (15.199948, 0.0, 13.068975)\n",
      "3000 (15.164927, 0.0, 13.125074)\n",
      "[12.823902]\n",
      "0 (23.589031, 11.687504, 0.0050736982)\n",
      "1000 (13.783058, 0.78215104, 10.499456)\n",
      "2000 (13.757699, 0.8308444, 10.357822)\n",
      "3000 (13.731749, 0.7647886, 10.444544)\n",
      "4000 (13.727054, 0.7662469, 10.456328)\n",
      "5000 (13.752615, 0.7576297, 10.464705)\n",
      "[12.823902]\n",
      "0 (33.237015, 16.46875, 0.005074567)\n",
      "1000 (12.961733, 0.0, 12.8347225)\n",
      "2000 (12.895821, 0.004121653, 12.849939)\n",
      "3000 (12.883742, 0.0055344375, 12.866079)\n",
      "[12.692158]\n",
      "0 (28.413023, 14.078127, 0.005074205)\n",
      "1000 (12.952747, 0.061755627, 12.644191)\n",
      "2000 (12.960801, 0.15082714, 12.539428)\n",
      "[12.660494]\n",
      "0 (26.001026, 12.882815, 0.0050739753)\n",
      "1000 (14.005619, 0.23239248, 11.261356)\n",
      "2000 (13.969374, 0.17684267, 11.451202)\n",
      "3000 (13.952642, 0.101707235, 11.490779)\n",
      "4000 (13.983356, 0.2900786, 11.312088)\n",
      "[11.482445]\n",
      "0 (24.795029, 12.285161, 0.0050738393)\n",
      "1000 (13.98769, 0.59083295, 10.867843)\n",
      "2000 (13.92101, 0.67523694, 10.734907)\n",
      "tick 5\n",
      "[10000000000.0]\n",
      "0 (0.045191307, 0.020916216, 0.0040188963)\n",
      "1000 (0.041392222, 0.021008782, 1.874535e-05)\n",
      "2000 (0.04139256, 0.021007912, 2.1455111e-05)\n",
      "[10000000000.0]\n",
      "0 (0.41587, 0.2091481, 0.0041541723)\n",
      "1000 (0.4120432, 0.2084966, 0.0020810205)\n",
      "2000 (0.41204405, 0.20850158, 0.002086387)\n",
      "[10000000000.0]\n",
      "0 (4.1213403, 2.091449, 0.0041907663)\n",
      "1000 (3.924133, 1.9280363, 0.2292435)\n",
      "2000 (3.9241142, 1.9280943, 0.22856653)\n",
      "[10000000000.0]\n",
      "0 (41.175682, 20.914448, 0.0041952403)\n",
      "1000 (11.741462, 0.13519105, 11.5424)\n",
      "2000 (11.700565, 0.07432947, 11.482719)\n",
      "3000 (11.399205, 0.0, 11.399205)\n",
      "4000 (11.4145975, 0.096245386, 11.313673)\n",
      "5000 (11.468827, 0.15435657, 11.31447)\n",
      "[11.270861]\n",
      "0 (22.648514, 11.50295, 0.004194823)\n",
      "1000 (12.025737, 2.2728207, 8.375546)\n",
      "2000 (11.716024, 1.5477532, 8.818447)\n",
      "3000 (11.694224, 1.5534408, 8.7886095)\n",
      "4000 (11.692975, 1.5508852, 8.7987385)\n",
      "5000 (11.696428, 1.5312438, 8.791789)\n",
      "[11.270861]\n",
      "0 (31.912098, 16.208702, 0.004195093)\n",
      "1000 (13.412111, 0.9535823, 10.999966)\n",
      "2000 (13.386016, 0.82122767, 11.179012)\n",
      "3000 (13.372782, 0.908409, 11.155758)\n",
      "[11.270861]\n",
      "0 (36.54389, 18.561573, 0.0041951765)\n",
      "1000 (13.5773535, 0.14367409, 12.117173)\n",
      "2000 (13.459706, 0.3481, 12.034713)\n",
      "3000 (13.4506235, 0.0, 12.318981)\n",
      "4000 (13.392377, 0.054912336, 12.221268)\n",
      "[11.270861]\n",
      "0 (34.227993, 17.38514, 0.004195139)\n",
      "1000 (13.668871, 1.2557364, 11.286514)\n",
      "2000 (13.691548, 1.1667067, 11.377436)\n",
      "[11.270861]\n",
      "0 (35.38594, 17.97336, 0.0041951574)\n",
      "1000 (13.709118, 0.8547798, 11.66797)\n",
      "2000 (13.749768, 0.7606345, 11.776321)\n",
      "tick 6\n",
      "[10000000000.0]\n",
      "0 (0.037873555, 0.012076332, 0.0053321677)\n",
      "1000 (0.03280437, 0.012204009, 1.430711e-05)\n",
      "2000 (0.032812297, 0.012203562, 2.3918543e-05)\n",
      "[10000000000.0]\n",
      "0 (0.33081836, 0.12075794, 0.0054131495)\n",
      "1000 (0.32662538, 0.12080761, 0.0015768174)\n",
      "2000 (0.32662585, 0.12081342, 0.0015625813)\n",
      "[10000000000.0]\n",
      "0 (3.2594655, 1.2075734, 0.005422755)\n",
      "1000 (3.1203945, 1.0846442, 0.16617996)\n",
      "2000 (3.120383, 1.0843879, 0.16663933)\n",
      "[10000000000.0]\n",
      "0 (32.545845, 12.075729, 0.005423734)\n",
      "1000 (10.292493, 0.0, 9.889128)\n",
      "2000 (10.29747, 0.0, 9.913347)\n",
      "[9.7997055]\n",
      "0 (17.902655, 6.6416516, 0.005423649)\n",
      "1000 (9.282421, 0.0, 6.8752007)\n",
      "2000 (9.296301, 0.0, 6.916554)\n",
      "[6.7659817]\n",
      "0 (10.581059, 3.9246132, 0.0054235132)\n",
      "1000 (7.987941, 0.6584287, 4.4234896)\n",
      "2000 (7.9890327, 0.6675918, 4.3958344)\n",
      "[6.7659817]\n",
      "0 (14.241857, 5.2831316, 0.0054235975)\n",
      "1000 (8.712814, 0.005855275, 6.1474276)\n",
      "2000 (8.711072, 0.0057011074, 6.140436)\n",
      "[6.1404]\n",
      "0 (12.411458, 4.603873, 0.0054235617)\n",
      "1000 (8.417641, 0.04435654, 5.714823)\n",
      "2000 (8.415775, 0.026276566, 5.7465725)\n",
      "[5.7840614]\n",
      "0 (11.496259, 4.264243, 0.0054235384)\n",
      "1000 (8.277303, 0.37253088, 5.08996)\n",
      "2000 (8.275803, 0.36415902, 5.1078186)\n",
      "3000 (8.277124, 0.35897267, 5.120203)\n",
      "tick 7\n",
      "[10000000000.0]\n",
      "0 (0.05273331, 0.021648396, 0.005896505)\n",
      "1000 (0.0470494, 0.021767356, 1.533454e-05)\n",
      "2000 (0.047057897, 0.021767484, 2.5445908e-05)\n",
      "[10000000000.0]\n",
      "0 (0.4743632, 0.21647756, 0.006004867)\n",
      "1000 (0.4689637, 0.21614061, 0.0017089996)\n",
      "2000 (0.4689701, 0.21613899, 0.0017245837)\n",
      "[10000000000.0]\n",
      "0 (4.689609, 2.1647708, 0.006029832)\n",
      "1000 (4.5217347, 1.9951986, 0.19558996)\n",
      "2000 (4.5217347, 1.9959081, 0.19475836)\n",
      "[10000000000.0]\n",
      "0 (46.84182, 21.6477, 0.0060333465)\n",
      "1000 (15.895967, 0.0, 15.750689)\n",
      "2000 (15.101173, 0.0, 15.062194)\n",
      "3000 (15.025581, 0.00014124066, 15.002254)\n",
      "4000 (15.038045, 0.041062452, 14.980056)\n",
      "5000 (15.057838, 0.06990395, 14.921981)\n",
      "6000 (15.053067, 0.009671785, 15.043395)\n",
      "[14.875265]\n",
      "0 (25.765717, 11.906235, 0.0060330126)\n",
      "1000 (18.472515, 2.913061, 9.128727)\n",
      "2000 (18.470284, 2.910728, 9.138397)\n",
      "[14.875265]\n",
      "0 (36.303764, 16.776966, 0.0060332264)\n",
      "1000 (15.164941, 0.0, 15.12385)\n",
      "2000 (14.990939, 0.015814176, 14.965039)\n",
      "3000 (15.050592, 0.053668536, 14.792532)\n",
      "[14.850464]\n",
      "0 (31.034744, 14.341602, 0.006033136)\n",
      "1000 (19.565853, 0.46040455, 14.377972)\n",
      "2000 (19.55163, 0.37116686, 14.621825)\n",
      "3000 (19.541536, 0.33399624, 14.7107525)\n",
      "4000 (19.544039, 0.34369516, 14.718775)\n",
      "[14.850464]\n",
      "0 (33.669254, 15.559284, 0.0060331845)\n",
      "1000 (15.069352, 0.07260672, 14.948517)\n",
      "2000 (14.972169, 0.060224008, 14.851908)\n",
      "3000 (14.96011, 0.008282746, 14.866254)\n",
      "4000 (14.949522, 0.13263495, 14.735386)\n",
      "5000 (14.947282, 0.0, 14.837816)\n",
      "6000 (14.918033, 0.042012196, 14.824238)\n",
      "7000 (15.003367, 0.18384826, 14.700229)\n",
      "[14.7310095]\n",
      "0 (32.351997, 14.950442, 0.0060331617)\n",
      "1000 (18.353092, 0.01827544, 17.011002)\n",
      "2000 (18.358755, 0.019639136, 17.036627)\n",
      "tick 8\n",
      "[10000000000.0]\n",
      "0 (0.053615548, 0.024067564, 0.0052929986)\n",
      "1000 (0.0486193, 0.024187861, 1.8759238e-05)\n",
      "2000 (0.048624005, 0.024187423, 2.6060381e-05)\n",
      "[10000000000.0]\n",
      "0 (0.4885729, 0.2406662, 0.005357544)\n",
      "1000 (0.48431253, 0.24028012, 0.002085642)\n",
      "2000 (0.48431283, 0.24028271, 0.0020734065)\n",
      "[10000000000.0]\n",
      "0 (4.837507, 2.4066455, 0.005365165)\n",
      "1000 (4.636997, 2.2173514, 0.23977019)\n",
      "2000 (4.6370783, 2.2170568, 0.23902345)\n",
      "[10000000000.0]\n",
      "0 (48.326775, 24.066431, 0.005365961)\n",
      "1000 (15.291654, 0.039247133, 15.001661)\n",
      "2000 (15.2136345, 0.0, 15.142514)\n",
      "3000 (15.22648, 0.07302103, 15.065697)\n",
      "[15.020634]\n",
      "0 (26.582142, 13.236539, 0.0053658863)\n",
      "1000 (14.326199, 0.055230267, 14.255146)\n",
      "2000 (14.331918, 0.062493045, 14.183077)\n",
      "3000 (14.339569, 0.0, 14.307991)\n",
      "4000 (14.350268, 0.13551421, 14.105613)\n",
      "[14.12566]\n",
      "0 (15.709823, 7.821592, 0.0053657745)\n",
      "1000 (13.114682, 5.161698, 2.86177)\n",
      "2000 (13.11548, 5.1611714, 2.8587668)\n",
      "[14.12566]\n",
      "0 (21.14598, 10.529064, 0.0053658457)\n",
      "1000 (11.71945, 1.4886504, 10.062133)\n",
      "2000 (11.697772, 1.4627442, 10.100122)\n",
      "[14.12566]\n",
      "0 (23.864061, 11.882801, 0.005365869)\n",
      "1000 (11.8398, 0.8942806, 10.910425)\n",
      "2000 (11.805401, 0.9313459, 10.765513)\n",
      "3000 (11.800154, 0.9058098, 10.809962)\n",
      "[14.12566]\n",
      "0 (25.223104, 12.55967, 0.0053658774)\n",
      "1000 (14.316703, 0.23610836, 13.598757)\n",
      "2000 (14.325153, 0.1980869, 13.616812)\n",
      "tick 9\n",
      "[10000000000.0]\n",
      "0 (0.03771609, 0.012393753, 0.005925891)\n",
      "1000 (0.03214202, 0.012521211, 1.9096631e-05)\n",
      "2000 (0.032151274, 0.012519763, 3.091216e-05)\n",
      "[10000000000.0]\n",
      "0 (0.32390627, 0.12393604, 0.006014429)\n",
      "1000 (0.31953254, 0.12397242, 0.002114041)\n",
      "2000 (0.3195324, 0.1239714, 0.0021173141)\n",
      "[10000000000.0]\n",
      "0 (3.1849318, 1.2393595, 0.006024404)\n",
      "1000 (2.9659991, 1.0905548, 0.28536394)\n",
      "2000 (2.9662652, 1.0875212, 0.28940803)\n",
      "[10000000000.0]\n",
      "0 (31.795084, 12.393591, 0.0060254107)\n",
      "1000 (8.45694, 0.0, 8.380757)\n",
      "2000 (8.441632, 0.0, 8.414147)\n",
      "3000 (8.386863, 0.005516626, 8.337427)\n",
      "4000 (8.422612, 0.0, 8.375256)\n",
      "[8.203364]\n",
      "0 (17.490007, 6.8164754, 0.006025318)\n",
      "1000 (9.08302, 2.0564578, 5.2543845)\n",
      "2000 (9.078516, 2.0531638, 5.2607183)\n",
      "3000 (9.089146, 2.0464942, 5.274459)\n",
      "4000 (9.101661, 2.0301135, 5.296836)\n",
      "[8.203364]\n",
      "0 (24.642546, 9.605033, 0.006025381)\n",
      "1000 (10.301801, 1.0923142, 8.587484)\n",
      "2000 (10.2707, 1.1015533, 8.605669)\n",
      "3000 (10.348949, 1.195143, 8.44076)\n",
      "[8.203364]\n",
      "0 (28.218819, 10.9993105, 0.006025397)\n",
      "1000 (8.686874, 0.07888241, 8.543233)\n",
      "2000 (8.608116, 0.0, 8.47015)\n",
      "3000 (8.538741, 0.0, 8.496817)\n",
      "4000 (8.523334, 0.08230773, 8.346049)\n",
      "5000 (8.519324, 0.07129414, 8.384659)\n",
      "6000 (8.510499, 0.0, 8.445442)\n",
      "[8.203364]\n",
      "0 (26.430681, 10.302174, 0.0060253893)\n",
      "1000 (10.43876, 1.0464648, 8.834528)\n",
      "2000 (10.405054, 1.0138816, 8.878671)\n",
      "3000 (10.398044, 1.0107162, 8.8940325)\n",
      "[8.203364]\n",
      "0 (27.324749, 10.650743, 0.0060253935)\n",
      "1000 (8.671589, 0.053752817, 8.582601)\n",
      "2000 (8.638182, 0.0, 8.638182)\n",
      "3000 (8.62443, 0.1007085, 8.464872)\n",
      "4000 (8.680764, 0.0, 8.481125)\n",
      "tick 10\n",
      "[10000000000.0]\n",
      "0 (0.04383284, 0.018484874, 0.0043732715)\n",
      "1000 (0.03964319, 0.01856435, 1.4861596e-05)\n",
      "2000 (0.039645623, 0.01856353, 2.018417e-05)\n",
      "[10000000000.0]\n",
      "0 (0.39907658, 0.18483642, 0.0044892197)\n",
      "1000 (0.39492205, 0.18419722, 0.0017268872)\n",
      "2000 (0.39492372, 0.1842005, 0.0017314167)\n",
      "[10000000000.0]\n",
      "0 (3.9503832, 1.8483342, 0.004518087)\n",
      "1000 (3.7827744, 1.6879078, 0.19918072)\n",
      "2000 (3.7827208, 1.6877539, 0.19953674)\n",
      "[10000000000.0]\n",
      "0 (39.46317, 18.483295, 0.004521562)\n",
      "1000 (11.472504, 0.22810993, 11.1794405)\n",
      "2000 (11.379742, 0.005489923, 11.158667)\n",
      "3000 (11.378247, 0.0, 11.325493)\n",
      "4000 (11.3489275, 0.0, 11.257643)\n",
      "[10.673405]\n",
      "0 (21.706776, 10.165814, 0.0045212414)\n",
      "1000 (10.865805, 0.011055642, 9.444846)\n",
      "2000 (10.869863, 0.04132522, 9.423397)\n",
      "3000 (10.864918, 0.036621053, 9.428817)\n",
      "[9.280857]\n",
      "0 (12.828581, 6.007076, 0.0045207487)\n",
      "1000 (9.785845, 2.7600687, 4.4134264)\n",
      "2000 (9.786867, 2.7744746, 4.3960633)\n",
      "[9.280857]\n",
      "0 (17.267677, 8.086444, 0.004521059)\n",
      "1000 (10.437135, 0.12751131, 8.583891)\n",
      "2000 (10.433763, 0.12700541, 8.595126)\n",
      "3000 (10.430947, 0.10668451, 8.623117)\n",
      "[9.280857]\n",
      "0 (19.487228, 9.12613, 0.0045211613)\n",
      "1000 (10.710133, 0.08631598, 8.743139)\n",
      "2000 (10.722649, 0.0, 8.935835)\n",
      "3000 (10.687113, 0.13881473, 8.763845)\n",
      "4000 (10.6702385, 0.032118782, 8.841303)\n",
      "5000 (10.6854, 0.15739034, 8.710562)\n",
      "[8.798771]\n",
      "0 (18.377455, 8.606289, 0.0045211124)\n",
      "1000 (10.543146, 0.09419024, 8.711088)\n",
      "2000 (10.526745, 0.0, 8.795809)\n",
      "3000 (10.549529, 0.054632526, 8.769348)\n",
      "tick 11\n",
      "[10000000000.0]\n",
      "0 (0.044212606, 0.021481052, 0.0051698186)\n",
      "1000 (0.03930285, 0.021617284, 1.640739e-05)\n",
      "2000 (0.03930883, 0.021616831, 2.479466e-05)\n",
      "[10000000000.0]\n",
      "0 (0.3956483, 0.21480604, 0.005229266)\n",
      "1000 (0.39138597, 0.2145924, 0.0018617306)\n",
      "2000 (0.3913875, 0.214577, 0.0018724131)\n",
      "[10000000000.0]\n",
      "0 (3.9094176, 2.1480565, 0.0052358266)\n",
      "1000 (3.747711, 1.9752136, 0.19161835)\n",
      "2000 (3.7477143, 1.9752611, 0.19175299)\n",
      "[10000000000.0]\n",
      "0 (39.04703, 21.480558, 0.005236487)\n",
      "1000 (11.916007, 0.0, 11.794022)\n",
      "2000 (11.839437, 0.0446044, 11.794832)\n",
      "3000 (11.87034, 0.14186916, 11.717577)\n",
      "4000 (11.821424, 0.0, 11.803394)\n",
      "5000 (11.841752, 0.079117395, 11.762634)\n",
      "[11.694874]\n",
      "0 (21.47823, 11.814308, 0.005236428)\n",
      "1000 (12.312054, 1.3553499, 9.407498)\n",
      "2000 (12.322526, 1.443658, 9.284146)\n",
      "[11.694874]\n",
      "0 (30.262629, 16.647432, 0.0052364646)\n",
      "1000 (11.876471, 0.062803045, 11.813667)\n",
      "2000 (11.467873, 0.1890749, 11.22839)\n",
      "3000 (11.471527, 0.0, 11.440565)\n",
      "4000 (11.416092, 0.0, 11.416092)\n",
      "5000 (11.429685, 0.0, 11.407322)\n",
      "6000 (11.382811, 0.0062195812, 11.376591)\n",
      "[11.285767]\n",
      "0 (25.870434, 14.230872, 0.0052364506)\n",
      "1000 (12.409854, 0.81025726, 10.656519)\n",
      "2000 (12.403982, 0.8182986, 10.630474)\n",
      "[11.285767]\n",
      "0 (28.066532, 15.439153, 0.005236458)\n",
      "1000 (11.932581, 0.060118448, 11.789295)\n",
      "2000 (11.928368, 0.19086456, 11.6571865)\n",
      "3000 (11.8992195, 0.015274371, 11.8714905)\n",
      "4000 (11.871134, 0.041878875, 11.828991)\n",
      "5000 (11.897542, 0.0027387987, 11.883714)\n",
      "6000 (11.879308, 0.042252447, 11.830128)\n",
      "[11.285767]\n",
      "0 (26.968481, 14.835011, 0.005236454)\n",
      "1000 (12.379569, 0.5222704, 10.95631)\n",
      "2000 (12.395556, 0.48781735, 11.001789)\n",
      "3000 (12.377368, 0.51800144, 10.947447)\n",
      "tick 12\n",
      "[10000000000.0]\n",
      "0 (0.03650978, 0.0151375, 0.0037939418)\n",
      "1000 (0.0329377, 0.015235039, 1.3845072e-05)\n",
      "2000 (0.03293772, 0.015233141, 1.7183662e-05)\n",
      "[10000000000.0]\n",
      "0 (0.3310101, 0.15137333, 0.0038581993)\n",
      "1000 (0.32783726, 0.15074067, 0.0018562326)\n",
      "2000 (0.32783842, 0.1507398, 0.0018624607)\n",
      "[10000000000.0]\n",
      "0 (3.2753787, 1.5137295, 0.0038659442)\n",
      "1000 (3.1090808, 1.3254353, 0.19935578)\n",
      "2000 (3.1089976, 1.3237927, 0.20226464)\n",
      "[10000000000.0]\n",
      "0 (32.718983, 15.137288, 0.0038667482)\n",
      "1000 (9.335446, 0.0, 9.116447)\n",
      "2000 (9.313269, 0.019052602, 9.114536)\n",
      "[8.829773]\n",
      "0 (17.997183, 8.32551, 0.0038666744)\n",
      "1000 (8.653758, 0.11935635, 6.7869086)\n",
      "2000 (8.619708, 0.15388687, 6.7394934)\n",
      "3000 (8.611509, 0.028430397, 6.83667)\n",
      "[6.849433]\n",
      "0 (10.63628, 4.919619, 0.0038665603)\n",
      "1000 (7.768156, 1.1360078, 4.47938)\n",
      "2000 (7.7662497, 1.13585, 4.4585085)\n",
      "[6.849433]\n",
      "0 (14.316732, 6.622564, 0.0038666315)\n",
      "1000 (7.946545, 0.016213072, 5.687052)\n",
      "2000 (7.9376593, 0.06516195, 5.7100887)\n",
      "3000 (7.9516788, 0.048736136, 5.7337713)\n",
      "[5.521563]\n",
      "0 (12.476504, 5.7710905, 0.0038665994)\n",
      "1000 (8.148546, 0.8212837, 5.4716487)\n",
      "2000 (8.137284, 0.75995165, 5.5433874)\n",
      "3000 (8.138178, 0.7970147, 5.4975424)\n",
      "[5.521563]\n",
      "0 (13.396619, 6.196827, 0.0038666185)\n",
      "1000 (7.851114, 0.12497081, 5.4632993)\n",
      "2000 (7.8439827, 0.1111374, 5.4798193)\n",
      "tick 13\n",
      "[10000000000.0]\n",
      "0 (0.049141295, 0.019855244, 0.0047718724)\n",
      "1000 (0.044552658, 0.019943777, 1.5546548e-05)\n",
      "2000 (0.044558164, 0.01994278, 2.4050787e-05)\n",
      "[10000000000.0]\n",
      "0 (0.44850838, 0.19855092, 0.0048178025)\n",
      "1000 (0.44392595, 0.19787152, 0.0017440114)\n",
      "2000 (0.44392586, 0.19786763, 0.0017535554)\n",
      "[10000000000.0]\n",
      "0 (4.441725, 1.9855078, 0.0048225047)\n",
      "1000 (4.278861, 1.8297062, 0.172231)\n",
      "2000 (4.2788796, 1.8298829, 0.17198414)\n",
      "[10000000000.0]\n",
      "0 (44.37384, 19.855076, 0.0048229787)\n",
      "1000 (12.837464, 0.011293031, 12.794539)\n",
      "2000 (12.837307, 0.019848444, 12.788828)\n",
      "3000 (12.864799, 0.024503328, 12.669693)\n",
      "4000 (12.8853, 0.0, 12.749432)\n",
      "5000 (12.894235, 0.0, 12.753933)\n",
      "[12.651707]\n",
      "0 (24.407784, 10.920293, 0.004822936)\n",
      "1000 (12.265794, 0.11072798, 10.213022)\n",
      "2000 (12.275395, 0.06517099, 10.245636)\n",
      "3000 (12.303082, 0.003823286, 10.386988)\n",
      "[10.361328]\n",
      "0 (14.424753, 6.4529, 0.00482287)\n",
      "1000 (12.503372, 4.6576486, 2.222743)\n",
      "2000 (12.503615, 4.6589794, 2.21912)\n",
      "[10.361328]\n",
      "0 (19.416267, 8.686596, 0.00482291)\n",
      "1000 (12.386442, 0.5819835, 8.712318)\n",
      "2000 (12.326656, 0.6064765, 8.792892)\n",
      "3000 (12.325126, 0.6196356, 8.755518)\n",
      "[10.361328]\n",
      "0 (21.912025, 9.803444, 0.0048229233)\n",
      "1000 (12.041612, 0.2905498, 9.869139)\n",
      "2000 (12.085453, 0.3717982, 9.701317)\n",
      "[10.361328]\n",
      "0 (20.664146, 9.24502, 0.0048229173)\n",
      "1000 (11.920213, 0.33583343, 9.689827)\n",
      "2000 (11.943351, 0.28529203, 9.804716)\n",
      "tick 14\n",
      "[10000000000.0]\n",
      "0 (0.057973456, 0.025845312, 0.004715546)\n",
      "1000 (0.053461082, 0.025918255, 2.0284073e-05)\n",
      "2000 (0.05346831, 0.025917131, 2.9915424e-05)\n",
      "[10000000000.0]\n",
      "0 (0.53743434, 0.2584494, 0.0048665116)\n",
      "1000 (0.5326389, 0.25735924, 0.0021851272)\n",
      "2000 (0.5326458, 0.25738195, 0.0021743434)\n",
      "[10000000000.0]\n",
      "0 (5.3305492, 2.584485, 0.004884766)\n",
      "1000 (5.1264334, 2.3830671, 0.21808836)\n",
      "2000 (5.1264305, 2.3830836, 0.21820283)\n",
      "[10000000000.0]\n",
      "0 (53.261528, 25.844845, 0.004886647)\n",
      "1000 (16.313416, 0.06517229, 16.18568)\n",
      "2000 (16.262938, 0.008433916, 16.183647)\n",
      "3000 (16.27214, 0.15203008, 16.12011)\n",
      "4000 (16.333344, 0.07195435, 16.226425)\n",
      "5000 (16.307936, 0.023249246, 16.251232)\n",
      "[16.148748]\n",
      "0 (29.29604, 14.214666, 0.0048864763)\n",
      "1000 (16.377626, 3.022104, 12.180294)\n",
      "2000 (16.431221, 2.984895, 12.326104)\n",
      "[16.148748]\n",
      "0 (41.278786, 20.029757, 0.004886585)\n",
      "1000 (16.410988, 0.60312665, 15.800083)\n",
      "2000 (16.415611, 0.62578034, 15.75634)\n",
      "[16.148748]\n",
      "0 (47.27016, 22.937302, 0.0048866174)\n",
      "1000 (16.657393, 0.078727946, 16.464958)\n",
      "2000 (16.616879, 0.03425375, 16.565536)\n",
      "3000 (16.663353, 0.13207269, 16.53128)\n",
      "4000 (16.632435, 0.21629189, 16.411776)\n",
      "[16.148748]\n",
      "0 (44.274475, 21.483528, 0.004886602)\n",
      "1000 (16.658106, 0.20391704, 16.44508)\n",
      "2000 (16.682842, 0.21747372, 16.40481)\n",
      "[16.148748]\n",
      "0 (42.77663, 20.756643, 0.0048865946)\n",
      "1000 (16.607567, 0.21469617, 16.295895)\n",
      "2000 (16.615072, 0.12074425, 16.34277)\n",
      "tick 15\n",
      "[10000000000.0]\n",
      "0 (0.041583795, 0.01866702, 0.005474169)\n",
      "1000 (0.036408458, 0.018778212, 2.0366706e-05)\n",
      "2000 (0.03641276, 0.018777704, 2.7412058e-05)\n",
      "[10000000000.0]\n",
      "0 (0.3666522, 0.186665, 0.005566464)\n",
      "1000 (0.36210576, 0.1861139, 0.002191888)\n",
      "2000 (0.362108, 0.18609962, 0.0022155389)\n",
      "[10000000000.0]\n",
      "0 (3.6164236, 1.8666447, 0.0055766883)\n",
      "1000 (3.4135325, 1.698466, 0.22592464)\n",
      "2000 (3.4135299, 1.6976931, 0.22763602)\n",
      "[10000000000.0]\n",
      "0 (36.114033, 18.66644, 0.0055777235)\n",
      "1000 (10.866678, 0.09626637, 10.763552)\n",
      "2000 (10.785826, 0.008212663, 10.776043)\n",
      "3000 (10.838235, 0.056580164, 10.738094)\n",
      "[10.635967]\n",
      "0 (19.86523, 10.266543, 0.005577631)\n",
      "1000 (10.852456, 1.6472731, 9.065982)\n",
      "2000 (10.827542, 1.5838401, 9.173024)\n",
      "3000 (10.822623, 1.5367644, 9.201185)\n",
      "[10.635967]\n",
      "0 (27.98963, 14.466492, 0.005577689)\n",
      "1000 (10.763514, 0.0, 10.68774)\n",
      "2000 (10.732058, 0.05257726, 10.647932)\n",
      "[10.596067]\n",
      "0 (23.927433, 12.366518, 0.0055776667)\n",
      "1000 (11.094815, 0.79154176, 10.2353)\n",
      "2000 (10.854616, 0.16292945, 10.648193)\n",
      "3000 (10.825832, 0.28071448, 10.459946)\n",
      "4000 (10.795184, 0.0900253, 10.599577)\n",
      "5000 (10.781064, 0.07901476, 10.676538)\n",
      "6000 (10.782331, 0.06466543, 10.66276)\n",
      "7000 (10.773121, 0.1199402, 10.641626)\n",
      "[10.570221]\n",
      "0 (21.89633, 11.316529, 0.005577648)\n",
      "1000 (10.977832, 1.229725, 9.640035)\n",
      "2000 (10.948203, 1.2540565, 9.587451)\n",
      "3000 (10.943303, 1.2576076, 9.622271)\n",
      "4000 (10.934329, 1.2628951, 9.66367)\n",
      "[10.570221]\n",
      "0 (22.911879, 11.841523, 0.0055776574)\n",
      "1000 (10.968218, 0.86472297, 10.029887)\n",
      "2000 (10.967191, 0.8769153, 10.036993)\n",
      "3000 (10.976105, 0.8870213, 9.990874)\n",
      "tick 16\n",
      "[10000000000.0]\n",
      "0 (0.048107572, 0.02168366, 0.005257278)\n",
      "1000 (0.043147907, 0.021815125, 2.2174927e-05)\n",
      "2000 (0.043158397, 0.021814479, 3.480225e-05)\n",
      "[10000000000.0]\n",
      "0 (0.43382257, 0.21683046, 0.0053294096)\n",
      "1000 (0.4293356, 0.21608403, 0.0023733075)\n",
      "2000 (0.42933965, 0.21608584, 0.002377042)\n",
      "[10000000000.0]\n",
      "0 (4.2902584, 2.1682982, 0.0053370427)\n",
      "1000 (4.066917, 1.9369191, 0.26096374)\n",
      "2000 (4.0661936, 1.936951, 0.26086923)\n",
      "[10000000000.0]\n",
      "0 (42.854546, 21.68298, 0.0053378073)\n",
      "1000 (12.894683, 0.08298788, 12.525234)\n",
      "2000 (12.754207, 0.05202303, 12.558985)\n",
      "3000 (12.766805, 0.0, 12.609587)\n",
      "[12.479104]\n",
      "0 (23.572403, 11.925637, 0.0053377375)\n",
      "1000 (12.049519, 1.3261719, 9.120773)\n",
      "2000 (11.956704, 1.1115623, 9.122236)\n",
      "3000 (11.944218, 1.0443702, 9.117222)\n",
      "[12.479104]\n",
      "0 (33.213478, 16.804308, 0.005337782)\n",
      "1000 (12.911019, 0.12335453, 11.8740635)\n",
      "2000 (12.866278, 0.008668951, 11.919635)\n",
      "3000 (12.910526, 0.16678205, 11.800548)\n",
      "[11.918766]\n",
      "0 (28.392939, 14.364973, 0.005337763)\n",
      "1000 (12.439244, 0.642401, 10.332155)\n",
      "2000 (12.385152, 0.6237629, 10.337508)\n",
      "[11.918766]\n",
      "0 (30.803205, 15.5846405, 0.005337772)\n",
      "1000 (12.466881, 0.2601759, 10.999844)\n",
      "2000 (12.449573, 0.21635795, 11.032051)\n",
      "[11.918766]\n",
      "0 (32.00834, 16.194471, 0.0053377785)\n",
      "1000 (13.017973, 0.008486301, 11.83533)\n",
      "2000 (12.889041, 0.14544868, 11.657573)\n",
      "3000 (12.876629, 0.09355532, 11.639045)\n",
      "tick 17\n",
      "[10000000000.0]\n",
      "0 (0.037191875, 0.013948777, 0.0036434866)\n",
      "1000 (0.03377751, 0.014035918, 2.2078702e-05)\n",
      "2000 (0.033777703, 0.014035509, 2.4661713e-05)\n",
      "[10000000000.0]\n",
      "0 (0.33916262, 0.13948372, 0.0036872812)\n",
      "1000 (0.3356551, 0.13839673, 0.0022508872)\n",
      "2000 (0.3356547, 0.13838701, 0.0022623604)\n",
      "[10000000000.0]\n",
      "0 (3.3584363, 1.39483, 0.0036921576)\n",
      "1000 (3.147328, 1.1884454, 0.24930206)\n",
      "2000 (3.1472528, 1.1896056, 0.24820669)\n",
      "[10000000000.0]\n",
      "0 (33.55112, 13.948291, 0.0036926619)\n",
      "1000 (7.312665, 0.0, 7.312665)\n",
      "2000 (7.272813, 0.0, 7.17026)\n",
      "3000 (7.35194, 0.0, 7.149785)\n",
      "[7.109839]\n",
      "0 (18.454782, 7.6715612, 0.0036926186)\n",
      "1000 (7.1662607, 0.0, 6.0848885)\n",
      "2000 (7.155237, 0.022967512, 6.0756955)\n",
      "3000 (7.1603017, 0.011092621, 6.0486245)\n",
      "[5.9896116]\n",
      "0 (10.90661, 4.5331964, 0.0036925464)\n",
      "1000 (6.6088114, 0.026466781, 5.6233664)\n",
      "2000 (6.619115, 0.00550247, 5.6951056)\n",
      "[5.621334]\n",
      "0 (7.1325235, 2.9640129, 0.0036924572)\n",
      "1000 (6.013469, 1.8377122, 1.4508288)\n",
      "2000 (6.013207, 1.8365451, 1.4550966)\n",
      "[5.621334]\n",
      "0 (9.019567, 3.7486045, 0.0036925133)\n",
      "1000 (7.122566, 2.0374296, 2.14323)\n",
      "2000 (7.046802, 1.6935061, 2.7666445)\n",
      "3000 (7.0461707, 1.6970932, 2.7679346)\n",
      "[5.621334]\n",
      "0 (9.963088, 4.1408997, 0.003692531)\n",
      "1000 (6.533218, 0.099232614, 5.395326)\n",
      "2000 (6.5195518, 0.079531, 5.4145546)\n",
      "tick 18\n",
      "[10000000000.0]\n",
      "0 (0.044294663, 0.013993482, 0.0062523894)\n",
      "1000 (0.03828859, 0.014085508, 1.0914318e-05)\n",
      "2000 (0.03829424, 0.014085249, 1.8944038e-05)\n",
      "[10000000000.0]\n",
      "0 (0.3867728, 0.13993144, 0.0063611716)\n",
      "1000 (0.38175556, 0.1399798, 0.0012817242)\n",
      "2000 (0.3817556, 0.14001852, 0.0012226861)\n",
      "[10000000000.0]\n",
      "0 (3.8104799, 1.3993123, 0.0063732257)\n",
      "1000 (3.694825, 1.3029926, 0.13935351)\n",
      "2000 (3.6948116, 1.3027982, 0.14001465)\n",
      "[10000000000.0]\n",
      "0 (38.047432, 13.993119, 0.006374448)\n",
      "1000 (14.448529, 0.0, 14.0839205)\n",
      "2000 (14.379393, 0.010537244, 14.075816)\n",
      "3000 (14.426278, 0.07065449, 14.113007)\n",
      "[13.474819]\n",
      "0 (20.928959, 7.696219, 0.006374332)\n",
      "1000 (12.718923, 0.08699158, 8.371928)\n",
      "2000 (12.719429, 0.09059608, 8.379258)\n",
      "3000 (12.705138, 0.0, 8.50359)\n",
      "4000 (12.713668, 0.06050485, 8.388229)\n",
      "[8.450854]\n",
      "0 (12.3697195, 4.547764, 0.0063741663)\n",
      "1000 (10.491285, 3.0866795, 2.1594894)\n",
      "2000 (10.491403, 3.0864162, 2.1514783)\n",
      "[8.450854]\n",
      "0 (16.64934, 6.121991, 0.0063742716)\n",
      "1000 (11.658036, 0.5944552, 6.5732965)\n",
      "2000 (11.656552, 0.5951386, 6.5722804)\n",
      "[8.450854]\n",
      "0 (18.789148, 6.909105, 0.006374305)\n",
      "1000 (12.271067, 0.18334648, 7.920125)\n",
      "2000 (12.267887, 0.15727827, 7.942459)\n",
      "3000 (12.260798, 0.09495304, 8.050144)\n",
      "[8.12383]\n",
      "0 (17.719242, 6.515547, 0.006374289)\n",
      "1000 (11.918316, 0.13248973, 7.457143)\n",
      "2000 (11.918028, 0.13465849, 7.463003)\n",
      "tick 19\n",
      "[10000000000.0]\n",
      "0 (0.037944883, 0.011956217, 0.0058898954)\n",
      "1000 (0.03236899, 0.012095297, 1.3360484e-05)\n",
      "2000 (0.032372326, 0.012095211, 1.8797135e-05)\n",
      "[10000000000.0]\n",
      "0 (0.3265107, 0.11955595, 0.0059693567)\n",
      "1000 (0.32228982, 0.11982584, 0.0015445409)\n",
      "2000 (0.32229245, 0.119833484, 0.0015372054)\n",
      "[10000000000.0]\n",
      "0 (3.2113829, 1.1955531, 0.005978534)\n",
      "1000 (3.0711994, 1.0629218, 0.17986274)\n",
      "2000 (3.0711532, 1.0632762, 0.1795584)\n",
      "[10000000000.0]\n",
      "0 (32.060017, 11.955521, 0.005979471)\n",
      "1000 (9.903072, 0.010937072, 9.75705)\n",
      "2000 (9.857829, 0.0, 9.8329525)\n",
      "3000 (9.931615, 0.0, 9.858704)\n",
      "[9.653352]\n",
      "0 (17.635702, 6.575538, 0.005979386)\n",
      "1000 (8.922742, 0.08775685, 8.033625)\n",
      "2000 (8.881027, 0.008765584, 8.069889)\n",
      "3000 (8.873286, 0.018998463, 8.129979)\n",
      "4000 (8.867589, 0.006296402, 8.154409)\n",
      "[8.047]\n",
      "0 (10.423542, 3.885545, 0.005979254)\n",
      "1000 (8.172705, 1.8368698, 2.888525)\n",
      "2000 (8.171252, 1.8266301, 2.8958519)\n",
      "[8.047]\n",
      "0 (14.029623, 5.2305427, 0.005979331)\n",
      "1000 (9.64127, 1.2439121, 5.276491)\n",
      "2000 (9.641794, 1.251516, 5.2644234)\n",
      "[8.047]\n",
      "0 (15.832664, 5.903041, 0.0059793624)\n",
      "1000 (8.778358, 0.0, 7.4118366)\n",
      "2000 (8.73833, 0.0, 7.3520947)\n",
      "3000 (8.7499275, 0.0, 7.417772)\n",
      "[7.2714987]\n",
      "0 (14.931143, 5.5667906, 0.005979348)\n",
      "1000 (9.81777, 1.1057934, 6.306179)\n",
      "2000 (9.815918, 1.1280031, 6.256007)\n",
      "3000 (9.816576, 1.1260638, 6.2550025)\n",
      "tick 20\n",
      "[10000000000.0]\n",
      "0 (0.042370073, 0.013609415, 0.0050171018)\n",
      "1000 (0.037676364, 0.0137753375, 2.6611282e-05)\n",
      "2000 (0.037677776, 0.013774089, 2.9162107e-05)\n",
      "[10000000000.0]\n",
      "0 (0.37859052, 0.13608666, 0.0050707497)\n",
      "1000 (0.3743127, 0.13520528, 0.0026271474)\n",
      "2000 (0.37431252, 0.13519154, 0.0026502702)\n",
      "[10000000000.0]\n",
      "0 (3.7402623, 1.3608562, 0.0050764782)\n",
      "1000 (3.5061836, 1.1113353, 0.26319355)\n",
      "2000 (3.5062594, 1.1095282, 0.26414877)\n",
      "[10000000000.0]\n",
      "0 (37.356934, 13.608553, 0.005077062)\n",
      "1000 (13.53099, 0.07259188, 11.17142)\n",
      "2000 (13.010122, 0.00288973, 11.854643)\n",
      "3000 (13.035445, 0.0, 11.705166)\n",
      "[10.90819]\n",
      "0 (20.5486, 7.4847045, 0.0050770077)\n",
      "1000 (11.564409, 0.014969093, 7.4575024)\n",
      "2000 (11.53002, 0.0682035, 7.407672)\n",
      "3000 (11.50431, 0.0064904746, 7.483541)\n",
      "4000 (11.5280485, 0.06391109, 7.5304823)\n",
      "[7.3794956]\n",
      "0 (12.144431, 4.422781, 0.0050769215)\n",
      "1000 (9.160429, 1.175252, 2.9895968)\n",
      "2000 (9.160011, 1.1690241, 3.006359)\n",
      "[7.3794956]\n",
      "0 (16.346514, 5.953742, 0.0050769723)\n",
      "1000 (10.840996, 0.5825532, 5.1235857)\n",
      "2000 (10.844986, 0.6071739, 5.094091)\n",
      "[7.3794956]\n",
      "0 (18.447556, 6.719223, 0.0050769933)\n",
      "1000 (11.065701, 0.075478286, 7.061138)\n",
      "2000 (11.107327, 0.09509501, 7.1450443)\n",
      "[7.3794956]\n",
      "0 (19.49808, 7.101965, 0.0050770007)\n",
      "1000 (11.322789, 0.043344144, 7.4385014)\n",
      "2000 (11.334398, 0.05249508, 7.4648476)\n",
      "tick 21\n",
      "[10000000000.0]\n",
      "0 (0.050514847, 0.023373177, 0.0051911008)\n",
      "1000 (0.045608267, 0.023490425, 2.0417676e-05)\n",
      "2000 (0.04561316, 0.023489062, 2.90501e-05)\n",
      "[10000000000.0]\n",
      "0 (0.45848006, 0.23372906, 0.005251306)\n",
      "1000 (0.4539766, 0.23301004, 0.002344063)\n",
      "2000 (0.4539783, 0.2330084, 0.0023480628)\n",
      "[10000000000.0]\n",
      "0 (4.5375366, 2.3372889, 0.0052575977)\n",
      "1000 (4.3076324, 2.1009145, 0.30107194)\n",
      "2000 (4.3076367, 2.1007452, 0.30229318)\n",
      "[10000000000.0]\n",
      "0 (45.328037, 23.372885, 0.005258235)\n",
      "1000 (12.8724985, 0.14977321, 12.69699)\n",
      "2000 (12.931318, 0.3742939, 12.542816)\n",
      "[12.704943]\n",
      "0 (24.932793, 12.855091, 0.0052581755)\n",
      "1000 (12.272737, 3.1269507, 8.854416)\n",
      "2000 (12.303655, 3.0586383, 8.933755)\n",
      "[12.704943]\n",
      "0 (35.13041, 18.113987, 0.0052582165)\n",
      "1000 (12.168759, 0.12063299, 11.914883)\n",
      "2000 (12.095258, 0.10189668, 11.883717)\n",
      "[11.631226]\n",
      "0 (30.031607, 15.484542, 0.0052581998)\n",
      "1000 (12.317822, 1.2515779, 10.596737)\n",
      "2000 (12.35536, 1.1836197, 10.778396)\n",
      "[11.631226]\n",
      "0 (32.58101, 16.799265, 0.005258208)\n",
      "1000 (12.601126, 0.2501539, 11.391041)\n",
      "2000 (12.596878, 0.09638167, 11.508012)\n",
      "3000 (12.594086, 0.11667863, 11.519217)\n",
      "4000 (12.670721, 0.0, 11.64046)\n",
      "[11.565528]\n",
      "0 (31.306309, 16.141903, 0.005258203)\n",
      "1000 (12.539076, 0.7449938, 10.828342)\n",
      "2000 (12.303846, 0.31635353, 11.34087)\n",
      "3000 (12.3161125, 0.3855339, 11.303204)\n",
      "4000 (12.328032, 0.29784533, 11.390757)\n",
      "5000 (12.303541, 0.49191076, 11.302504)\n",
      "6000 (12.101919, 0.18505439, 11.787669)\n",
      "7000 (12.108219, 0.15463929, 11.822537)\n",
      "tick 22\n",
      "[10000000000.0]\n",
      "0 (0.049189445, 0.02143654, 0.005847182)\n",
      "1000 (0.043600444, 0.021560464, 1.8051831e-05)\n",
      "2000 (0.043603875, 0.021558689, 2.4116736e-05)\n",
      "[10000000000.0]\n",
      "0 (0.4393308, 0.21435896, 0.0059202937)\n",
      "1000 (0.43428028, 0.21387178, 0.0019229816)\n",
      "2000 (0.43428093, 0.21386975, 0.0019348022)\n",
      "[10000000000.0]\n",
      "0 (4.34002, 2.1435819, 0.005927955)\n",
      "1000 (4.166446, 1.9593521, 0.20701475)\n",
      "2000 (4.166421, 1.959289, 0.20728174)\n",
      "[10000000000.0]\n",
      "0 (43.34684, 21.435814, 0.005928727)\n",
      "1000 (13.327045, 0.0, 13.251513)\n",
      "2000 (13.3627405, 0.063079454, 13.202589)\n",
      "[13.184238]\n",
      "0 (23.84343, 11.789697, 0.005928655)\n",
      "1000 (13.179591, 0.364674, 11.294414)\n",
      "2000 (13.15815, 0.38718486, 11.261991)\n",
      "[13.184238]\n",
      "0 (33.59513, 16.612753, 0.0059287027)\n",
      "1000 (13.355314, 0.026290145, 13.209408)\n",
      "2000 (13.323893, 0.087684765, 13.042027)\n",
      "3000 (13.321945, 0.046667803, 13.136954)\n",
      "4000 (13.301327, 0.07763304, 13.185231)\n",
      "[13.054999]\n",
      "0 (28.719282, 14.201226, 0.005928684)\n",
      "1000 (13.497261, 0.18161963, 12.292595)\n",
      "2000 (13.280178, 0.16948006, 12.326619)\n",
      "3000 (13.282007, 0.082255, 12.325798)\n",
      "[12.358381]\n",
      "0 (26.281353, 12.995459, 0.005928671)\n",
      "1000 (13.362776, 0.25013304, 11.940277)\n",
      "2000 (13.362394, 0.19276983, 12.041575)\n",
      "3000 (13.378722, 0.2943754, 11.85646)\n",
      "[12.358381]\n",
      "0 (27.500315, 13.598343, 0.0059286775)\n",
      "1000 (13.39687, 0.098864935, 12.410883)\n",
      "2000 (13.368666, 0.02414419, 12.450989)\n",
      "3000 (13.380586, 0.05896241, 12.412306)\n",
      "tick 23\n",
      "[10000000000.0]\n",
      "0 (0.041080344, 0.013254328, 0.005999214)\n",
      "1000 (0.035366345, 0.013391504, 1.5405174e-05)\n",
      "2000 (0.035368677, 0.013391658, 1.8539646e-05)\n",
      "[10000000000.0]\n",
      "0 (0.356862, 0.13253807, 0.0060605123)\n",
      "1000 (0.3521242, 0.13255899, 0.0017088652)\n",
      "2000 (0.35212895, 0.13257533, 0.0017021324)\n",
      "[10000000000.0]\n",
      "0 (3.5140722, 1.3253764, 0.006067073)\n",
      "1000 (3.3572402, 1.1877314, 0.18648784)\n",
      "2000 (3.357003, 1.1882957, 0.18528885)\n",
      "[10000000000.0]\n",
      "0 (35.086105, 13.253759, 0.0060677435)\n",
      "1000 (10.719785, 0.52397025, 10.122801)\n",
      "2000 (10.63249, 0.58235896, 10.037832)\n",
      "3000 (10.641965, 0.6246959, 10.001867)\n",
      "4000 (10.673855, 0.62917197, 9.975175)\n",
      "[10000000000.0]\n",
      "0 (350.8065, 132.53758, 0.006067807)\n",
      "1000 (14.205846, 0.32770252, 13.878143)\n",
      "2000 (13.649595, 0.0, 13.649595)\n",
      "3000 (13.557571, 0.0, 13.557571)\n",
      "[13.385671]\n",
      "0 (192.94626, 72.895676, 0.0060678003)\n",
      "1000 (13.352224, 0.0, 13.352224)\n",
      "2000 (13.595641, 0.0, 13.595641)\n",
      "[13.077398]\n",
      "0 (114.016205, 43.07472, 0.006067794)\n",
      "1000 (12.975129, 0.03597708, 12.918314)\n",
      "2000 (12.915446, 0.0, 12.894987)\n",
      "[12.834728]\n",
      "0 (74.55115, 28.164238, 0.0060677812)\n",
      "1000 (13.9577055, 0.042833026, 13.859918)\n",
      "2000 (13.837282, 0.07059434, 13.766687)\n",
      "3000 (13.866183, 0.05731481, 13.808868)\n",
      "[12.834728]\n",
      "0 (54.818626, 20.709, 0.0060677677)\n",
      "1000 (13.029568, 0.069160536, 12.960407)\n",
      "2000 (11.06867, 0.0, 11.06867)\n",
      "3000 (11.178376, 0.0, 11.178376)\n",
      "tick 24\n",
      "[10000000000.0]\n",
      "0 (0.044804543, 0.014674805, 0.0062844064)\n",
      "1000 (0.03874253, 0.014778267, 7.831606e-06)\n",
      "2000 (0.038745414, 0.014777182, 1.3959387e-05)\n",
      "[10000000000.0]\n",
      "0 (0.3916201, 0.14674044, 0.0064315116)\n",
      "1000 (0.38653815, 0.14697212, 0.0009776913)\n",
      "2000 (0.3865421, 0.14696619, 0.0009999431)\n",
      "[10000000000.0]\n",
      "0 (3.8583212, 1.4673957, 0.0064478153)\n",
      "1000 (3.7532413, 1.3665327, 0.13841426)\n",
      "2000 (3.7533178, 1.366486, 0.13847622)\n",
      "[10000000000.0]\n",
      "0 (38.525177, 14.67395, 0.0064494703)\n",
      "1000 (12.71929, 0.027254201, 12.543196)\n",
      "2000 (12.647592, 0.0, 12.624018)\n",
      "3000 (12.713695, 0.02503667, 12.511107)\n",
      "[12.520142]\n",
      "0 (21.191746, 8.070673, 0.0064493204)\n",
      "1000 (10.371652, 0.021833498, 9.637764)\n",
      "2000 (10.360214, 0.06789299, 9.563289)\n",
      "3000 (10.345114, 0.19171244, 9.33346)\n",
      "4000 (10.301842, 0.13901304, 9.413576)\n",
      "5000 (10.3509, 0.18701561, 9.331155)\n",
      "[9.684589]\n",
      "0 (12.525034, 4.7690334, 0.0064490894)\n",
      "1000 (8.896968, 1.5520197, 4.514667)\n",
      "2000 (8.829104, 1.4070764, 4.9856963)\n",
      "3000 (8.83031, 1.4713424, 4.876851)\n",
      "[9.684589]\n",
      "0 (16.858393, 6.4198537, 0.006449233)\n",
      "1000 (10.542059, 0.97299564, 7.192621)\n",
      "2000 (10.559284, 1.0175256, 7.1489873)\n",
      "[9.684589]\n",
      "0 (19.025072, 7.245264, 0.0064492836)\n",
      "1000 (9.964498, 0.39008915, 8.849788)\n",
      "2000 (9.939437, 0.4275867, 8.749192)\n",
      "3000 (9.941442, 0.41850916, 8.763962)\n",
      "4000 (9.957919, 0.4726065, 8.682526)\n",
      "[9.684589]\n",
      "0 (20.108408, 7.657968, 0.006449304)\n",
      "1000 (10.28104, 0.23926403, 9.198085)\n",
      "2000 (10.281349, 0.20089045, 9.301342)\n",
      "3000 (10.263549, 0.22573707, 9.274157)\n"
     ]
    }
   ],
   "source": [
    "from nn_robust_attacks.l2_attack_tri import CarliniL2\n",
    "\n",
    "adv = CarliniL2(sess, model1, model2, model3).attack(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "\n",
    "np.save('inputs_tri_' + str(true_label) + '.csv', inputs)\n",
    "np.save('adv_tri_' + str(true_label) + '.csv', adv)\n",
    "np.save('targets_tri_' + str(true_label) + '.csv', targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3905384128>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Valid:\")\n",
    "plt.imshow(inputs[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3904ebca58>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Adversarial:\")\n",
    "plt.imshow(adv[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3904eaa550>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Perturbation')\n",
    "plt.imshow(adv[0][:,:,0] - inputs[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_confidence(image, model):\n",
    "    pr = model.predict(image)\n",
    "    pr = np.array([np.exp(x) for x in pr])\n",
    "    pr = pr / np.sum(pr)\n",
    "    image_class = model.predict_classes(image)\n",
    "    return 'Predicted {} : {:.7f}'.format(image_class[0], max(max(pr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:From /home/zainkhan/.local/share/virtualenvs/xu-jXQ59E2g/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "Model 1 Predicted 9 : 0.2748632\n",
      "Model 2 Predicted 9 : 0.2781032\n",
      "Model 3 Predicted 0 : 0.9488509\n",
      "1\n",
      "Model 1 Predicted 9 : 0.3509947\n",
      "Model 2 Predicted 9 : 0.3436402\n",
      "Model 3 Predicted 0 : 0.7343668\n",
      "2\n",
      "Model 1 Predicted 9 : 0.3459896\n",
      "Model 2 Predicted 9 : 0.4393218\n",
      "Model 3 Predicted 0 : 0.8888412\n",
      "3\n",
      "Model 1 Predicted 9 : 0.3966465\n",
      "Model 2 Predicted 0 : 0.7832109\n",
      "Model 3 Predicted 0 : 0.9750934\n",
      "4\n",
      "Model 1 Predicted 9 : 0.2618844\n",
      "Model 2 Predicted 0 : 0.4013896\n",
      "Model 3 Predicted 0 : 0.9068822\n",
      "5\n",
      "Model 1 Predicted 9 : 0.5111811\n",
      "Model 2 Predicted 9 : 0.4796142\n",
      "Model 3 Predicted 0 : 0.9087945\n",
      "6\n",
      "Model 1 Predicted 9 : 0.4854451\n",
      "Model 2 Predicted 0 : 0.9907546\n",
      "Model 3 Predicted 0 : 0.9673081\n",
      "7\n",
      "Model 1 Predicted 9 : 0.5340796\n",
      "Model 2 Predicted 9 : 0.5455490\n",
      "Model 3 Predicted 0 : 0.9923419\n",
      "8\n",
      "Model 1 Predicted 9 : 0.3572369\n",
      "Model 2 Predicted 0 : 0.3785561\n",
      "Model 3 Predicted 0 : 0.4922773\n",
      "9\n",
      "Model 1 Predicted 9 : 0.5051016\n",
      "Model 2 Predicted 9 : 0.5277202\n",
      "Model 3 Predicted 0 : 0.9959436\n",
      "10\n",
      "Model 1 Predicted 9 : 0.3754416\n",
      "Model 2 Predicted 0 : 0.4443603\n",
      "Model 3 Predicted 0 : 0.9502972\n",
      "11\n",
      "Model 1 Predicted 9 : 0.3656687\n",
      "Model 2 Predicted 9 : 0.3582335\n",
      "Model 3 Predicted 0 : 0.8911824\n",
      "12\n",
      "Model 1 Predicted 9 : 0.4983048\n",
      "Model 2 Predicted 9 : 0.4830115\n",
      "Model 3 Predicted 0 : 0.9684553\n",
      "13\n",
      "Model 1 Predicted 9 : 0.5169238\n",
      "Model 2 Predicted 9 : 0.4972343\n",
      "Model 3 Predicted 0 : 0.9932675\n",
      "14\n",
      "Model 1 Predicted 9 : 0.3600484\n",
      "Model 2 Predicted 9 : 0.4962456\n",
      "Model 3 Predicted 5 : 0.6862620\n",
      "15\n",
      "Model 1 Predicted 9 : 0.5272413\n",
      "Model 2 Predicted 9 : 0.4236540\n",
      "Model 3 Predicted 0 : 0.6702834\n",
      "16\n",
      "Model 1 Predicted 9 : 0.3538420\n",
      "Model 2 Predicted 9 : 0.3037378\n",
      "Model 3 Predicted 2 : 0.8827535\n",
      "17\n",
      "Model 1 Predicted 9 : 0.3624913\n",
      "Model 2 Predicted 0 : 0.4140297\n",
      "Model 3 Predicted 0 : 0.8538912\n",
      "18\n",
      "Model 1 Predicted 9 : 0.5224232\n",
      "Model 2 Predicted 0 : 0.9985055\n",
      "Model 3 Predicted 0 : 0.9999500\n",
      "19\n",
      "Model 1 Predicted 9 : 0.4992852\n",
      "Model 2 Predicted 0 : 0.5373734\n",
      "Model 3 Predicted 0 : 0.9786450\n",
      "20\n",
      "Model 1 Predicted 9 : 0.2758085\n",
      "Model 2 Predicted 0 : 0.9657487\n",
      "Model 3 Predicted 0 : 0.9910294\n",
      "21\n",
      "Model 1 Predicted 9 : 0.3440366\n",
      "Model 2 Predicted 9 : 0.3087061\n",
      "Model 3 Predicted 0 : 0.8569005\n",
      "22\n",
      "Model 1 Predicted 9 : 0.5125633\n",
      "Model 2 Predicted 9 : 0.4903760\n",
      "Model 3 Predicted 0 : 0.9998872\n",
      "23\n",
      "Model 1 Predicted 9 : 0.2816260\n",
      "Model 2 Predicted 9 : 0.4801714\n",
      "Model 3 Predicted 0 : 0.9097544\n",
      "24\n",
      "Model 1 Predicted 9 : 0.2847663\n",
      "Model 2 Predicted 9 : 0.4142112\n",
      "Model 3 Predicted 0 : 0.8328769\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, num_img):\n",
    "    print(i)\n",
    "    print('Model 1', get_label_confidence(adv[i][np.newaxis, ...], model1.model))\n",
    "    print('Model 2', get_label_confidence(adv[i][np.newaxis, ...], model2.model))\n",
    "    print('Model 3', get_label_confidence(adv[i][np.newaxis, ...], model3.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 5.08387939453125\n",
      "Standard Deviation 0.9281273\n"
     ]
    }
   ],
   "source": [
    "perturb = adv - inputs\n",
    "perturb_mean =  np.sum(perturb) / num_img \n",
    "perturb_std = np.std(np.array([sum(x) for x in perturb]))\n",
    "print('Mean', perturb_mean)\n",
    "print('Standard Deviation', perturb_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model 4 Predicted 9 : 0.6268160\n",
      "1\n",
      "Model 4 Predicted 0 : 0.3467971\n",
      "2\n",
      "Model 4 Predicted 9 : 0.7721281\n",
      "3\n",
      "Model 4 Predicted 0 : 0.9433358\n",
      "4\n",
      "Model 4 Predicted 3 : 0.9413667\n",
      "5\n",
      "Model 4 Predicted 2 : 0.5513410\n",
      "6\n",
      "Model 4 Predicted 0 : 0.9828698\n",
      "7\n",
      "Model 4 Predicted 0 : 0.9836392\n",
      "8\n",
      "Model 4 Predicted 0 : 0.8415120\n",
      "9\n",
      "Model 4 Predicted 0 : 0.9902375\n",
      "10\n",
      "Model 4 Predicted 5 : 0.4615895\n",
      "11\n",
      "Model 4 Predicted 0 : 0.6847674\n",
      "12\n",
      "Model 4 Predicted 0 : 0.5981404\n",
      "13\n",
      "Model 4 Predicted 0 : 0.9365160\n",
      "14\n",
      "Model 4 Predicted 0 : 0.8772315\n",
      "15\n",
      "Model 4 Predicted 0 : 0.8601555\n",
      "16\n",
      "Model 4 Predicted 9 : 0.4153365\n",
      "17\n",
      "Model 4 Predicted 0 : 0.7193800\n",
      "18\n",
      "Model 4 Predicted 0 : 0.9815810\n",
      "19\n",
      "Model 4 Predicted 0 : 0.9801328\n",
      "20\n",
      "Model 4 Predicted 0 : 0.9890976\n",
      "21\n",
      "Model 4 Predicted 5 : 0.7011885\n",
      "22\n",
      "Model 4 Predicted 0 : 0.9400018\n",
      "23\n",
      "Model 4 Predicted 0 : 0.6064667\n",
      "24\n",
      "Model 4 Predicted 0 : 0.5276427\n"
     ]
    }
   ],
   "source": [
    "# Transferability test\n",
    "for i in range(0, num_img):\n",
    "    print(i)\n",
    "    print('Model 4', get_label_confidence(adv[i][np.newaxis, ...], model4.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
